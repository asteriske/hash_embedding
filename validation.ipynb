{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hash_embedding\n",
    "import hash_embedding_verbose\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = hash_embedding.HashEmbedding(num_words=5, \n",
    "    num_hash_buckets=7, \n",
    "    embedding_width=3, \n",
    "    num_hash_func=4, \n",
    "    append_weight=True, \n",
    "    aggregation_mode='append', \n",
    "    random_seed=1138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_verbose = hash_embedding_verbose.HashEmbedding(num_words=5, \n",
    "    num_hash_buckets=7, \n",
    "    embedding_width=3, \n",
    "    num_hash_func=4, \n",
    "    append_weight=True, \n",
    "    aggregation_mode='append', \n",
    "    random_seed=1138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = he(tf.constant([[1,25,5384,900008],\n",
    "                      [23490,2347,123,15],\n",
    "                      [9234,234,1492,1224]],dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 16), dtype=float16, numpy=\n",
       "array([[[ 7.1526e-07, -2.1458e-06,  1.0073e-05,  8.7023e-06,\n",
       "         -1.9729e-05,  2.2292e-05, -4.7684e-07, -2.2650e-06,\n",
       "         -6.5565e-07,  1.8358e-05,  8.3447e-05,  2.5332e-05,\n",
       "          6.1512e-05, -1.0765e-04, -1.1027e-05,  4.1127e-04],\n",
       "        [-5.0664e-06,  1.4544e-05, -6.9082e-05,  2.3842e-07,\n",
       "         -9.0003e-06, -3.3379e-06, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  8.0466e-06, -6.2585e-06, -2.9802e-06,\n",
       "         -4.2152e-04,  1.5640e-04, -3.2735e-04,  2.0242e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5822e-05,\n",
       "          2.0862e-05,  1.1563e-05,  2.9802e-07, -8.9407e-07,\n",
       "          4.3511e-06, -1.0788e-05,  8.4639e-06,  3.9935e-06,\n",
       "          3.9458e-04,  5.6505e-04,  2.6643e-05, -2.7180e-04],\n",
       "        [ 3.5226e-05, -2.0564e-05, -1.1384e-05, -1.8239e-05,\n",
       "          1.4246e-05,  6.7353e-06, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -2.2233e-05, -1.0121e-04, -3.0756e-05,\n",
       "         -5.5599e-04, -4.5919e-04, -2.2697e-04, -4.9877e-04]],\n",
       "\n",
       "       [[-5.0664e-06,  1.4544e-05, -6.9082e-05,  2.3842e-07,\n",
       "         -9.0003e-06, -3.3379e-06, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  8.0466e-06, -6.2585e-06, -2.9802e-06,\n",
       "         -4.2152e-04,  1.5640e-04, -3.2735e-04,  2.0242e-04],\n",
       "        [-1.7881e-06,  5.0664e-06, -2.4199e-05, -1.2457e-05,\n",
       "         -5.6744e-05, -1.7226e-05,  2.2411e-05,  1.0204e-04,\n",
       "          3.0994e-05, -2.4438e-06,  1.9073e-06,  8.9407e-07,\n",
       "         -1.4782e-04, -2.7966e-04,  5.0306e-04, -6.1035e-05],\n",
       "        [ 3.5226e-05, -2.0564e-05, -1.1384e-05, -1.8239e-05,\n",
       "          1.4246e-05,  6.7353e-06, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -2.2233e-05, -1.0121e-04, -3.0756e-05,\n",
       "         -5.5599e-04, -4.5919e-04, -2.2697e-04, -4.9877e-04],\n",
       "        [-5.0664e-06,  1.4544e-05, -6.9082e-05,  2.3842e-07,\n",
       "         -9.0003e-06, -3.3379e-06, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  8.0466e-06, -6.2585e-06, -2.9802e-06,\n",
       "         -4.2152e-04,  1.5640e-04, -3.2735e-04,  2.0242e-04]],\n",
       "\n",
       "       [[ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5822e-05,\n",
       "          2.0862e-05,  1.1563e-05,  2.9802e-07, -8.9407e-07,\n",
       "          4.3511e-06, -1.0788e-05,  8.4639e-06,  3.9935e-06,\n",
       "          3.9458e-04,  5.6505e-04,  2.6643e-05, -2.7180e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5822e-05,\n",
       "          2.0862e-05,  1.1563e-05,  2.9802e-07, -8.9407e-07,\n",
       "          4.3511e-06, -1.0788e-05,  8.4639e-06,  3.9935e-06,\n",
       "          3.9458e-04,  5.6505e-04,  2.6643e-05, -2.7180e-04],\n",
       "        [-1.7881e-06,  5.0664e-06, -2.4199e-05, -1.2457e-05,\n",
       "         -5.6744e-05, -1.7226e-05,  2.2411e-05,  1.0204e-04,\n",
       "          3.0994e-05, -2.4438e-06,  1.9073e-06,  8.9407e-07,\n",
       "         -1.4782e-04, -2.7966e-04,  5.0306e-04, -6.1035e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5822e-05,\n",
       "          2.0862e-05,  1.1563e-05,  2.9802e-07, -8.9407e-07,\n",
       "          4.3511e-06, -1.0788e-05,  8.4639e-06,  3.9935e-06,\n",
       "          3.9458e-04,  5.6505e-04,  2.6643e-05, -2.7180e-04]]],\n",
       "      dtype=float16)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hash table values\ntf.Tensor([5 5 5 1 0], shape=(5,), dtype=int32)\ntf.Tensor([4 3 6 2 1], shape=(5,), dtype=int32)\ntf.Tensor([0 6 6 0 5], shape=(5,), dtype=int32)\ntf.Tensor([2 6 2 6 2], shape=(5,), dtype=int32)\n===========================================================\n===========================================================\n\nword importance\n<tf.Variable 'hash_embedding/Variable:0' shape=(5, 4) dtype=float16, numpy=\narray([[-1.4782e-04, -2.7966e-04,  5.0306e-04, -6.1035e-05],\n       [-5.5599e-04, -4.5919e-04, -2.2697e-04, -4.9877e-04],\n       [ 3.9458e-04,  5.6505e-04,  2.6643e-05, -2.7180e-04],\n       [-4.2152e-04,  1.5640e-04, -3.2735e-04,  2.0242e-04],\n       [ 6.1512e-05, -1.0765e-04, -1.1027e-05,  4.1127e-04]],\n      dtype=float16)>\n===========================================================\n===========================================================\n\nembedding matrix\n<tf.Variable 'hash_embedding/Variable:0' shape=(8, 3) dtype=float16, numpy=\narray([[ 0.       ,  0.       ,  0.       ],\n       [-0.06335  ,  0.03696  ,  0.0205   ],\n       [ 0.03976  , -0.03105  , -0.01471  ],\n       [-0.0808   ,  0.1831   , -0.207    ],\n       [ 0.001414 , -0.05756  , -0.02136  ],\n       [ 0.01203  , -0.03445  ,  0.1638   ],\n       [ 0.0446   ,  0.2029   ,  0.0616   ],\n       [ 0.1187   ,  0.0006037,  0.01096  ]], dtype=float16)>\n===========================================================\n===========================================================\n\nInput % num_words\ntf.Tensor(\n[[1 0 4 3]\n [0 2 3 0]\n [4 4 2 4]], shape=(3, 4), dtype=int64)\n===========================================================\n===========================================================\n\nInput + 3 % num_words\ntf.Tensor(\n[[4 3 2 1]\n [3 0 1 3]\n [2 2 0 2]], shape=(3, 4), dtype=int64)\n===========================================================\n===========================================================\n\nword_id_to_embedding_bucket\ntf.Tensor(\n[[5 5 0 1]\n [5 5 1 5]\n [0 0 5 0]], shape=(3, 4), dtype=int32)\n===========================================================\n===========================================================\n\nlooked up embedding\ntf.Tensor(\n[[[ 0.01203 -0.03445  0.1638 ]\n  [ 0.01203 -0.03445  0.1638 ]\n  [ 0.       0.       0.     ]\n  [-0.06335  0.03696  0.0205 ]]\n\n [[ 0.01203 -0.03445  0.1638 ]\n  [ 0.01203 -0.03445  0.1638 ]\n  [-0.06335  0.03696  0.0205 ]\n  [ 0.01203 -0.03445  0.1638 ]]\n\n [[ 0.       0.       0.     ]\n  [ 0.       0.       0.     ]\n  [ 0.01203 -0.03445  0.1638 ]\n  [ 0.       0.       0.     ]]], shape=(3, 4, 3), dtype=float16)\n===========================================================\n===========================================================\n\nfound importance\ntf.Tensor(\n[[ 6.151e-05 -4.215e-04  3.946e-04 -5.560e-04]\n [-4.215e-04 -1.478e-04 -5.560e-04 -4.215e-04]\n [ 3.946e-04  3.946e-04 -1.478e-04  3.946e-04]], shape=(3, 4), dtype=float16)\n===========================================================\n===========================================================\n\nadding to weighted_embeddings...\n[<tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 7.153e-07, -2.146e-06,  1.007e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 3.523e-05, -2.056e-05, -1.138e-05]],\n\n       [[-5.066e-06,  1.454e-05, -6.908e-05],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 3.523e-05, -2.056e-05, -1.138e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05]],\n\n       [[ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00]]], dtype=float16)>]\n===========================================================\n===========================================================\n\nword_id_to_embedding_bucket\ntf.Tensor(\n[[3 4 1 2]\n [4 6 2 4]\n [1 1 6 1]], shape=(3, 4), dtype=int32)\n===========================================================\n===========================================================\n\nlooked up embedding\ntf.Tensor(\n[[[-0.0808    0.1831   -0.207   ]\n  [ 0.001414 -0.05756  -0.02136 ]\n  [-0.06335   0.03696   0.0205  ]\n  [ 0.03976  -0.03105  -0.01471 ]]\n\n [[ 0.001414 -0.05756  -0.02136 ]\n  [ 0.0446    0.2029    0.0616  ]\n  [ 0.03976  -0.03105  -0.01471 ]\n  [ 0.001414 -0.05756  -0.02136 ]]\n\n [[-0.06335   0.03696   0.0205  ]\n  [-0.06335   0.03696   0.0205  ]\n  [ 0.0446    0.2029    0.0616  ]\n  [-0.06335   0.03696   0.0205  ]]], shape=(3, 4, 3), dtype=float16)\n===========================================================\n===========================================================\n\nfound importance\ntf.Tensor(\n[[-0.00010765  0.0001564   0.000565   -0.0004592 ]\n [ 0.0001564  -0.0002797  -0.0004592   0.0001564 ]\n [ 0.000565    0.000565   -0.0002797   0.000565  ]], shape=(3, 4), dtype=float16)\n===========================================================\n===========================================================\n\nadding to weighted_embeddings...\n[<tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 7.153e-07, -2.146e-06,  1.007e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 3.523e-05, -2.056e-05, -1.138e-05]],\n\n       [[-5.066e-06,  1.454e-05, -6.908e-05],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 3.523e-05, -2.056e-05, -1.138e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05]],\n\n       [[ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 8.702e-06, -1.973e-05,  2.229e-05],\n        [ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06]],\n\n       [[ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06],\n        [ 2.384e-07, -9.000e-06, -3.338e-06]],\n\n       [[-3.582e-05,  2.086e-05,  1.156e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05]]], dtype=float16)>]\n===========================================================\n===========================================================\n\nword_id_to_embedding_bucket\ntf.Tensor(\n[[6 0 5 0]\n [0 6 0 0]\n [5 5 6 5]], shape=(3, 4), dtype=int32)\n===========================================================\n===========================================================\n\nlooked up embedding\ntf.Tensor(\n[[[ 0.0446   0.2029   0.0616 ]\n  [ 0.       0.       0.     ]\n  [ 0.01203 -0.03445  0.1638 ]\n  [ 0.       0.       0.     ]]\n\n [[ 0.       0.       0.     ]\n  [ 0.0446   0.2029   0.0616 ]\n  [ 0.       0.       0.     ]\n  [ 0.       0.       0.     ]]\n\n [[ 0.01203 -0.03445  0.1638 ]\n  [ 0.01203 -0.03445  0.1638 ]\n  [ 0.0446   0.2029   0.0616 ]\n  [ 0.01203 -0.03445  0.1638 ]]], shape=(3, 4, 3), dtype=float16)\n===========================================================\n===========================================================\n\nfound importance\ntf.Tensor(\n[[-1.103e-05 -3.273e-04  2.664e-05 -2.270e-04]\n [-3.273e-04  5.031e-04 -2.270e-04 -3.273e-04]\n [ 2.664e-05  2.664e-05  5.031e-04  2.664e-05]], shape=(3, 4), dtype=float16)\n===========================================================\n===========================================================\n\nadding to weighted_embeddings...\n[<tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 7.153e-07, -2.146e-06,  1.007e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 3.523e-05, -2.056e-05, -1.138e-05]],\n\n       [[-5.066e-06,  1.454e-05, -6.908e-05],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 3.523e-05, -2.056e-05, -1.138e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05]],\n\n       [[ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 8.702e-06, -1.973e-05,  2.229e-05],\n        [ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06]],\n\n       [[ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06],\n        [ 2.384e-07, -9.000e-06, -3.338e-06]],\n\n       [[-3.582e-05,  2.086e-05,  1.156e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[-4.7684e-07, -2.2650e-06, -6.5565e-07],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06]]], dtype=float16)>]\n===========================================================\n===========================================================\n\nword_id_to_embedding_bucket\ntf.Tensor(\n[[6 2 2 6]\n [2 2 6 2]\n [2 2 2 2]], shape=(3, 4), dtype=int32)\n===========================================================\n===========================================================\n\nlooked up embedding\ntf.Tensor(\n[[[ 0.0446   0.2029   0.0616 ]\n  [ 0.03976 -0.03105 -0.01471]\n  [ 0.03976 -0.03105 -0.01471]\n  [ 0.0446   0.2029   0.0616 ]]\n\n [[ 0.03976 -0.03105 -0.01471]\n  [ 0.03976 -0.03105 -0.01471]\n  [ 0.0446   0.2029   0.0616 ]\n  [ 0.03976 -0.03105 -0.01471]]\n\n [[ 0.03976 -0.03105 -0.01471]\n  [ 0.03976 -0.03105 -0.01471]\n  [ 0.03976 -0.03105 -0.01471]\n  [ 0.03976 -0.03105 -0.01471]]], shape=(3, 4, 3), dtype=float16)\n===========================================================\n===========================================================\n\nfound importance\ntf.Tensor(\n[[ 4.113e-04  2.024e-04 -2.718e-04 -4.988e-04]\n [ 2.024e-04 -6.104e-05 -4.988e-04  2.024e-04]\n [-2.718e-04 -2.718e-04 -6.104e-05 -2.718e-04]], shape=(3, 4), dtype=float16)\n===========================================================\n===========================================================\n\nadding to weighted_embeddings...\n[<tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 7.153e-07, -2.146e-06,  1.007e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 3.523e-05, -2.056e-05, -1.138e-05]],\n\n       [[-5.066e-06,  1.454e-05, -6.908e-05],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 3.523e-05, -2.056e-05, -1.138e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05]],\n\n       [[ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 8.702e-06, -1.973e-05,  2.229e-05],\n        [ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06]],\n\n       [[ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06],\n        [ 2.384e-07, -9.000e-06, -3.338e-06]],\n\n       [[-3.582e-05,  2.086e-05,  1.156e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[-4.7684e-07, -2.2650e-06, -6.5565e-07],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 1.836e-05,  8.345e-05,  2.533e-05],\n        [ 8.047e-06, -6.258e-06, -2.980e-06],\n        [-1.079e-05,  8.464e-06,  3.994e-06],\n        [-2.223e-05, -1.012e-04, -3.076e-05]],\n\n       [[ 8.047e-06, -6.258e-06, -2.980e-06],\n        [-2.444e-06,  1.907e-06,  8.941e-07],\n        [-2.223e-05, -1.012e-04, -3.076e-05],\n        [ 8.047e-06, -6.258e-06, -2.980e-06]],\n\n       [[-1.079e-05,  8.464e-06,  3.994e-06],\n        [-1.079e-05,  8.464e-06,  3.994e-06],\n        [-2.444e-06,  1.907e-06,  8.941e-07],\n        [-1.079e-05,  8.464e-06,  3.994e-06]]], dtype=float16)>]\n===========================================================\n===========================================================\n\nconcat tensors\n[<tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 7.153e-07, -2.146e-06,  1.007e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 3.523e-05, -2.056e-05, -1.138e-05]],\n\n       [[-5.066e-06,  1.454e-05, -6.908e-05],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 3.523e-05, -2.056e-05, -1.138e-05],\n        [-5.066e-06,  1.454e-05, -6.908e-05]],\n\n       [[ 0.000e+00,  0.000e+00,  0.000e+00],\n        [ 0.000e+00,  0.000e+00,  0.000e+00],\n        [-1.788e-06,  5.066e-06, -2.420e-05],\n        [ 0.000e+00,  0.000e+00,  0.000e+00]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 8.702e-06, -1.973e-05,  2.229e-05],\n        [ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06]],\n\n       [[ 2.384e-07, -9.000e-06, -3.338e-06],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-1.824e-05,  1.425e-05,  6.735e-06],\n        [ 2.384e-07, -9.000e-06, -3.338e-06]],\n\n       [[-3.582e-05,  2.086e-05,  1.156e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05],\n        [-1.246e-05, -5.674e-05, -1.723e-05],\n        [-3.582e-05,  2.086e-05,  1.156e-05]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[-4.7684e-07, -2.2650e-06, -6.5565e-07],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00],\n        [-0.0000e+00, -0.0000e+00, -0.0000e+00]],\n\n       [[ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06],\n        [ 2.2411e-05,  1.0204e-04,  3.0994e-05],\n        [ 2.9802e-07, -8.9407e-07,  4.3511e-06]]], dtype=float16)>, <tf.Tensor: shape=(3, 4, 3), dtype=float16, numpy=\narray([[[ 1.836e-05,  8.345e-05,  2.533e-05],\n        [ 8.047e-06, -6.258e-06, -2.980e-06],\n        [-1.079e-05,  8.464e-06,  3.994e-06],\n        [-2.223e-05, -1.012e-04, -3.076e-05]],\n\n       [[ 8.047e-06, -6.258e-06, -2.980e-06],\n        [-2.444e-06,  1.907e-06,  8.941e-07],\n        [-2.223e-05, -1.012e-04, -3.076e-05],\n        [ 8.047e-06, -6.258e-06, -2.980e-06]],\n\n       [[-1.079e-05,  8.464e-06,  3.994e-06],\n        [-1.079e-05,  8.464e-06,  3.994e-06],\n        [-2.444e-06,  1.907e-06,  8.941e-07],\n        [-1.079e-05,  8.464e-06,  3.994e-06]]], dtype=float16)>]\nweighted average embedding:\ntf.Tensor(\n[[[ 7.1526e-07 -2.1458e-06  1.0073e-05  8.7023e-06 -1.9729e-05\n    2.2292e-05 -4.7684e-07 -2.2650e-06 -6.5565e-07  1.8358e-05\n    8.3447e-05  2.5332e-05]\n  [-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [ 3.5226e-05 -2.0564e-05 -1.1384e-05 -1.8239e-05  1.4246e-05\n    6.7353e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00 -2.2233e-05\n   -1.0121e-04 -3.0756e-05]]\n\n [[-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]\n  [-1.7881e-06  5.0664e-06 -2.4199e-05 -1.2457e-05 -5.6744e-05\n   -1.7226e-05  2.2411e-05  1.0204e-04  3.0994e-05 -2.4438e-06\n    1.9073e-06  8.9407e-07]\n  [ 3.5226e-05 -2.0564e-05 -1.1384e-05 -1.8239e-05  1.4246e-05\n    6.7353e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00 -2.2233e-05\n   -1.0121e-04 -3.0756e-05]\n  [-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]]\n\n [[ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [-1.7881e-06  5.0664e-06 -2.4199e-05 -1.2457e-05 -5.6744e-05\n   -1.7226e-05  2.2411e-05  1.0204e-04  3.0994e-05 -2.4438e-06\n    1.9073e-06  8.9407e-07]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]]], shape=(3, 4, 12), dtype=float16)\nweighted_emb\ntf.Tensor(\n[[[ 7.1526e-07 -2.1458e-06  1.0073e-05  8.7023e-06 -1.9729e-05\n    2.2292e-05 -4.7684e-07 -2.2650e-06 -6.5565e-07  1.8358e-05\n    8.3447e-05  2.5332e-05]\n  [-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [ 3.5226e-05 -2.0564e-05 -1.1384e-05 -1.8239e-05  1.4246e-05\n    6.7353e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00 -2.2233e-05\n   -1.0121e-04 -3.0756e-05]]\n\n [[-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]\n  [-1.7881e-06  5.0664e-06 -2.4199e-05 -1.2457e-05 -5.6744e-05\n   -1.7226e-05  2.2411e-05  1.0204e-04  3.0994e-05 -2.4438e-06\n    1.9073e-06  8.9407e-07]\n  [ 3.5226e-05 -2.0564e-05 -1.1384e-05 -1.8239e-05  1.4246e-05\n    6.7353e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00 -2.2233e-05\n   -1.0121e-04 -3.0756e-05]\n  [-5.0664e-06  1.4544e-05 -6.9082e-05  2.3842e-07 -9.0003e-06\n   -3.3379e-06 -0.0000e+00 -0.0000e+00 -0.0000e+00  8.0466e-06\n   -6.2585e-06 -2.9802e-06]]\n\n [[ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]\n  [-1.7881e-06  5.0664e-06 -2.4199e-05 -1.2457e-05 -5.6744e-05\n   -1.7226e-05  2.2411e-05  1.0204e-04  3.0994e-05 -2.4438e-06\n    1.9073e-06  8.9407e-07]\n  [ 0.0000e+00  0.0000e+00  0.0000e+00 -3.5822e-05  2.0862e-05\n    1.1563e-05  2.9802e-07 -8.9407e-07  4.3511e-06 -1.0788e-05\n    8.4639e-06  3.9935e-06]]], shape=(3, 4, 12), dtype=float16)\nimportances_this_word\ntf.Tensor(\n[[[ 6.1512e-05 -1.0765e-04 -1.1027e-05  4.1127e-04]\n  [-4.2152e-04  1.5640e-04 -3.2735e-04  2.0242e-04]\n  [ 3.9458e-04  5.6505e-04  2.6643e-05 -2.7180e-04]\n  [-5.5599e-04 -4.5919e-04 -2.2697e-04 -4.9877e-04]]\n\n [[-4.2152e-04  1.5640e-04 -3.2735e-04  2.0242e-04]\n  [-1.4782e-04 -2.7966e-04  5.0306e-04 -6.1035e-05]\n  [-5.5599e-04 -4.5919e-04 -2.2697e-04 -4.9877e-04]\n  [-4.2152e-04  1.5640e-04 -3.2735e-04  2.0242e-04]]\n\n [[ 3.9458e-04  5.6505e-04  2.6643e-05 -2.7180e-04]\n  [ 3.9458e-04  5.6505e-04  2.6643e-05 -2.7180e-04]\n  [-1.4782e-04 -2.7966e-04  5.0306e-04 -6.1035e-05]\n  [ 3.9458e-04  5.6505e-04  2.6643e-05 -2.7180e-04]]], shape=(3, 4, 4), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "bar = he_verbose(tf.constant([[1,25,5384,900008],\n",
    "                      [23490,2347,123,15],\n",
    "                      [9234,234,1492,1224]],dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 16), dtype=float16, numpy=\n",
       "array([[[-1.1921e-06,  3.9339e-06,  3.1590e-06,  1.1325e-06,\n",
       "         -7.8082e-06, -1.1802e-05,  4.3511e-05, -1.4269e-04,\n",
       "         -1.1533e-04, -1.7881e-07, -3.3379e-06, -1.7107e-05,\n",
       "          2.1040e-05,  2.4045e-04, -7.6675e-04,  1.8311e-04],\n",
       "        [-2.4199e-05,  7.9334e-05,  6.4135e-05,  4.1068e-05,\n",
       "          2.7478e-05, -2.4080e-05, -2.9802e-07, -6.8545e-06,\n",
       "         -3.5167e-05, -1.4305e-05, -3.6478e-05, -1.1742e-05,\n",
       "          4.2653e-04,  2.7013e-04,  3.7599e-04, -3.2234e-04],\n",
       "        [ 1.0329e-04,  6.9082e-05, -6.0618e-05,  2.6345e-05,\n",
       "          6.7055e-05,  2.1577e-05, -5.9605e-07, -1.5497e-06,\n",
       "         -5.3644e-07,  1.6451e-05,  1.0967e-05, -9.6560e-06,\n",
       "          6.7949e-04,  5.9271e-04, -1.3947e-05,  1.0806e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1856e-06,\n",
       "         -1.3232e-05, -4.2319e-06,  1.0133e-06,  2.1636e-05,\n",
       "          1.1104e-04, -7.1526e-07, -1.5736e-05, -8.0764e-05,\n",
       "          3.7599e-04, -1.1683e-04, -1.1873e-03,  8.6403e-04]],\n",
       "\n",
       "       [[-2.4199e-05,  7.9334e-05,  6.4135e-05,  4.1068e-05,\n",
       "          2.7478e-05, -2.4080e-05, -2.9802e-07, -6.8545e-06,\n",
       "         -3.5167e-05, -1.4305e-05, -3.6478e-05, -1.1742e-05,\n",
       "          4.2653e-04,  2.7013e-04,  3.7599e-04, -3.2234e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3447e-07,\n",
       "          5.8413e-06,  8.8215e-06, -9.7811e-05, -6.5446e-05,\n",
       "          5.7399e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          4.2033e-04, -1.8001e-04, -6.4373e-04,  7.8917e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1856e-06,\n",
       "         -1.3232e-05, -4.2319e-06,  1.0133e-06,  2.1636e-05,\n",
       "          1.1104e-04, -7.1526e-07, -1.5736e-05, -8.0764e-05,\n",
       "          3.7599e-04, -1.1683e-04, -1.1873e-03,  8.6403e-04],\n",
       "        [-2.4199e-05,  7.9334e-05,  6.4135e-05,  4.1068e-05,\n",
       "          2.7478e-05, -2.4080e-05, -2.9802e-07, -6.8545e-06,\n",
       "         -3.5167e-05, -1.4305e-05, -3.6478e-05, -1.1742e-05,\n",
       "          4.2653e-04,  2.7013e-04,  3.7599e-04, -3.2234e-04]],\n",
       "\n",
       "       [[ 1.0329e-04,  6.9082e-05, -6.0618e-05,  2.6345e-05,\n",
       "          6.7055e-05,  2.1577e-05, -5.9605e-07, -1.5497e-06,\n",
       "         -5.3644e-07,  1.6451e-05,  1.0967e-05, -9.6560e-06,\n",
       "          6.7949e-04,  5.9271e-04, -1.3947e-05,  1.0806e-04],\n",
       "        [ 1.0329e-04,  6.9082e-05, -6.0618e-05,  2.6345e-05,\n",
       "          6.7055e-05,  2.1577e-05, -5.9605e-07, -1.5497e-06,\n",
       "         -5.3644e-07,  1.6451e-05,  1.0967e-05, -9.6560e-06,\n",
       "          6.7949e-04,  5.9271e-04, -1.3947e-05,  1.0806e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3447e-07,\n",
       "          5.8413e-06,  8.8215e-06, -9.7811e-05, -6.5446e-05,\n",
       "          5.7399e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          4.2033e-04, -1.8001e-04, -6.4373e-04,  7.8917e-04],\n",
       "        [ 1.0329e-04,  6.9082e-05, -6.0618e-05,  2.6345e-05,\n",
       "          6.7055e-05,  2.1577e-05, -5.9605e-07, -1.5497e-06,\n",
       "         -5.3644e-07,  1.6451e-05,  1.0967e-05, -9.6560e-06,\n",
       "          6.7949e-04,  5.9271e-04, -1.3947e-05,  1.0806e-04]]],\n",
       "      dtype=float16)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}